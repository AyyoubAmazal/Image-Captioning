# Image-Captioning
This repository demonstrates Image Captioning using classical CNN–RNN pipelines as well as a state-of-the-art pretrained vision–language model. We explore and compare the following approaches:  VGG19 + LSTM  InceptionV3 + BiLSTM + Attention  BLIP (Bootstrapped Language–Image Pretraining
